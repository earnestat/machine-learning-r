---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 01-Introduction.md in _episodes_rmd/
title: "Introduction"
author: "Jorge Perez de Acha Chavez"
questions: 
- "What is Exploratory Data Analysis (EDA) and why is it useful?"
- "How can I do EDA in R?"
objectives: 
- "Use `caret` to preprocess data."
keypoints: 
- "Plots are always useful tools for getting to know your data."
- "Center and scale your numerical variables using the `caret` package."
output: html_document
---



## Getting set up computationally

First you'll install the necessary packages and then load them.


~~~
# Run this cell to install & load the required packages
# If you need to install them, uncomment the lines of code below
#install.packages("tidyverse")
#install.packages("kernlab")
#install.packages("ddalpha")
#install.packages("caret")
#install.packages("GGally")
#install.packages("gmodels")
#install.packages("glmnet", repos = "http://cran.us.r-project.org")
#install.packages("e1071")


# Load packages
library(tidyverse)
library(kernlab)
library(ddalpha)
library(caret)
library(GGally)
library(gmodels)
library(glmnet)
~~~
{: .language-r}



## Loading your data

It's time to import the first dataset that we'll work with, the [Breast Cancer Wisconsin (Diagnostic) Data Set](http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29) from the UCI Machine Learning repository.

Do this and check out the first several rows:


~~~
# Load data
df <- read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",
               col_names = FALSE)
# Check out head of dataframe
df %>% head()
~~~
{: .language-r}
> ## Discussion
>
> What are the variables in the dataset? Follow the link to UCI above to find out.
>
{: .discussion}

Before thinking about modeling, have a look at your data. There's no point in throwing a $10^4$ layer convolutional neural network (whatever that means) at your data before you even know what you're dealing with.

You'll first remove the first column, which is the unique identifier of each row:


~~~
# Remove first column 
df <- df[2:32]
# View head
df %>% head()
~~~
{: .language-r}

> ## Question
>
> How many features are there in this dataset?
>
{: .challenge}

> ## Discussion
>
> Why did we want to remove the unique identifier?
>
{: .discussion}

Now there are too many features to plot so you'll plot the first 5 in a pair-plot:
<!-- does this mean we're getting rid of features, or that we'll only plot the first five as opposed to the 32 -->


~~~
# Pair-plot of first 5 features
ggpairs(df[1:5], aes(colour=X2, alpha=0.4))
~~~
{: .language-r}

> ## Discussion
>
> What can you see here?
>
{: .discussion}

Note that the features have widely varying centers and scales (means and standard deviations) so we'll want to center and scale them in some situations. You'll use the caret package for this. You can read more about preprocessing with caret [here](https://topepo.github.io/caret/pre-processing.html#pp).
<!-- it is not entirely clear why it's necessary to perform scaling and centering.
perhaps briefly mention the other situations when center and scaling is not necessary? --> 


~~~
# Center & scale data
ppv <- preProcess(df, method = c("center", "scale"))
df_tr <- predict(ppv, df)
# Summarize first 5 columns
df_tr[1:5] %>% summary()
~~~
{: .language-r}


Now plot the centered & scaled features:


~~~
# Pair-plot of transformed data
ggpairs(df_tr[1:5], aes(colour=X2))
~~~
{: .language-r}

> ## Discussion
>
> How does this compare to your previous pairplot?
>
{: .discussion}
